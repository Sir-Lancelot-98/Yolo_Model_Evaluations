{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion via cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_occlusion(image, occlusion_type=\"rectangle\", mask_image_path=None):\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    if occlusion_type == \"rectangle\":\n",
    "        # Random occlusion with a black rectangle\n",
    "        x1, y1 = random.randint(0, w//2), random.randint(0, h//2)\n",
    "        x2, y2 = random.randint(x1 + w//4, w), random.randint(y1 + h//4, h)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 0), -1)\n",
    "    \n",
    "    elif occlusion_type == \"blur\":\n",
    "        # Random blur over an area\n",
    "        x1, y1 = random.randint(0, w//2), random.randint(0, h//2)\n",
    "        x2, y2 = random.randint(x1 + w//4, w), random.randint(y1 + h//4, h)\n",
    "        blurred_part = cv2.GaussianBlur(image[y1:y2, x1:x2], (21, 21), 30)\n",
    "        image[y1:y2, x1:x2] = blurred_part\n",
    "    \n",
    "    elif occlusion_type == \"sunglasses\":\n",
    "        # Draw sunglasses dynamically\n",
    "        y_offset = h // 3\n",
    "        x_offset = w // 4\n",
    "        sunglass_width = w // 2\n",
    "        sunglass_height = h // 6\n",
    "        \n",
    "        cv2.ellipse(image, (x_offset + sunglass_width // 4, y_offset), (sunglass_width // 4, sunglass_height // 2), 0, 0, 360, (0, 0, 0), -1)\n",
    "        cv2.ellipse(image, (x_offset + 3 * sunglass_width // 4, y_offset), (sunglass_width // 4, sunglass_height // 2), 0, 0, 360, (0, 0, 0), -1)\n",
    "        cv2.line(image, (x_offset + sunglass_width // 4, y_offset), (x_offset + 3 * sunglass_width // 4, y_offset), (0, 0, 0), 5)\n",
    "    \n",
    "    elif occlusion_type == \"mask\":\n",
    "        if mask_image_path and os.path.exists(mask_image_path):\n",
    "            # Load mask image with alpha channel\n",
    "            mask = cv2.imread(mask_image_path, cv2.IMREAD_UNCHANGED)\n",
    "            if mask is None or mask.shape[2] != 4:\n",
    "                print(f\"Error loading mask image: {mask_image_path}\")\n",
    "                return image\n",
    "            \n",
    "            mask_h, mask_w = mask.shape[:2]\n",
    "            \n",
    "            # Resize mask while maintaining aspect ratio\n",
    "            scale = (w / mask_w) * 0.9  # Slightly smaller than face width\n",
    "            new_w = int(mask_w * scale)\n",
    "            new_h = int(mask_h * scale)\n",
    "            mask = cv2.resize(mask, (new_w, new_h))\n",
    "            \n",
    "            # Define mask position (lower face)\n",
    "            x_offset = (w - new_w) // 2\n",
    "            y_offset = int(h * 0.65)  # Position around mouth/nose\n",
    "            \n",
    "            # Extract alpha channel for blending\n",
    "            alpha_s = mask[:, :, 3] / 255.0  # Normalize alpha channel\n",
    "            alpha_l = 1.0 - alpha_s\n",
    "            \n",
    "            for c in range(3):  # Blend each channel\n",
    "                image[y_offset:y_offset+new_h, x_offset:x_offset+new_w, c] = (\n",
    "                    alpha_s * mask[:, :, c] + alpha_l * image[y_offset:y_offset+new_h, x_offset:x_offset+new_w, c]\n",
    "                ).astype(np.uint8)\n",
    "        else:\n",
    "            # Draw a face mask dynamically if no mask image is provided\n",
    "            mask_top = h // 2\n",
    "            mask_bottom = int(h * 0.85)\n",
    "            mask_left = int(w * 0.25)\n",
    "            mask_right = int(w * 0.75)\n",
    "            cv2.rectangle(image, (mask_left, mask_top), (mask_right, mask_bottom), (50, 50, 50), -1)\n",
    "    \n",
    "    return image\n",
    "def process_images(input_folder, output_folder, occlusion_type=\"rectangle\", mask_image_path=None):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = add_occlusion(img, occlusion_type, mask_image_path)\n",
    "            cv2.imwrite(os.path.join(output_folder, filename), img)\n",
    "            \n",
    "# Example Usage\n",
    "input_folder = r\"D:\\Akash\\Work\\AI\\2025\\Research_Datasets\\celeba_hq\\images\\male\"\n",
    "output_folder = r\"D:\\Akash\\Work\\AI\\2025\\Research_Datasets\\celeba_hq\\output\"\n",
    "occlusion_type = \"rectangle\"  # Change to \"blur\", \"sunglasses\", or \"mask\" as needed\n",
    "mask_image_path = \"mask.png\"  # Provide a mask image path or None for dynamic mask\n",
    "\n",
    "process_images(input_folder, output_folder, occlusion_type, mask_image_path)\n",
    "\n",
    "# Display an example\n",
    "sample_img = cv2.imread(os.path.join(output_folder, os.listdir(output_folder)[0]))\n",
    "sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(sample_img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r\"Z:\\AI\\research_2023-\\TechnicalResearch\\202502_TC03\\OCHuman_遮蔽追加\\3_Annotation\\labels\"  # Change this if needed\n",
    "prefix = \"OCHuman_\"  # Change this to your desired prefix\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\") and filename != \"classes.txt\":\n",
    "        old_path = os.path.join(folder_path, filename)\n",
    "        new_path = os.path.join(folder_path, prefix + filename)\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f'Renamed: {filename} → {prefix + filename}')\n",
    "\n",
    "print(\"Renaming complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion inside YOLO Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5081/5081 [01:02<00:00, 80.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occlusion augmentation completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "image_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\images\"\n",
    "label_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\labels\"\n",
    "save_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\shahei\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Occlusion Parameters\n",
    "num_occlusions = (1, 5)  # Min and max occlusions per image\n",
    "occlusion_size = (20, 100)  # Min and max box size\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]  # Red, Green, Blue, Yellow\n",
    "\n",
    "# Process Images\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "for image_file in tqdm(image_files):\n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.replace('.jpg', '.txt'))\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Read YOLO labels\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    for label in labels:\n",
    "        parts = label.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        _, x_center, y_center, bbox_w, bbox_h = map(float, parts)\n",
    "        x1 = int((x_center - bbox_w / 2) * w)\n",
    "        y1 = int((y_center - bbox_h / 2) * h)\n",
    "        x2 = int((x_center + bbox_w / 2) * w)\n",
    "        y2 = int((y_center + bbox_h / 2) * h)\n",
    "        \n",
    "        # Apply random occlusions inside the annotation box\n",
    "        for _ in range(random.randint(*num_occlusions)):\n",
    "            box_size = random.randint(*occlusion_size)\n",
    "            occl_x1 = random.randint(x1, max(x1, x2 - box_size))\n",
    "            occl_y1 = random.randint(y1, max(y1, y2 - box_size))\n",
    "            occl_x2 = occl_x1 + box_size\n",
    "            occl_y2 = occl_y1 + box_size\n",
    "            color = random.choice(colors)\n",
    "            cv2.rectangle(img, (occl_x1, occl_y1), (occl_x2, occl_y2), color, -1)\n",
    "    \n",
    "    # Save modified image\n",
    "    save_path = os.path.join(save_folder, image_file)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "print(\"Occlusion augmentation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occlusion with constraints :\n",
    "1. min = 25% of bb and max = 75% of bb\n",
    "2. Only one Occlusion per BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5081/5081 [02:23<00:00, 35.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occlusion augmentation completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "image_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\images\"\n",
    "label_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\labels\"\n",
    "save_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\shahei_bigger\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Occlusion Parameters\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]  # Red, Green, Blue, Yellow\n",
    "\n",
    "# Process Images\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "for image_file in tqdm(image_files):\n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.replace('.jpg', '.txt'))\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Read YOLO labels\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    for label in labels:\n",
    "        parts = label.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        _, x_center, y_center, bbox_w, bbox_h = map(float, parts)\n",
    "        x1 = int((x_center - bbox_w / 2) * w)\n",
    "        y1 = int((y_center - bbox_h / 2) * h)\n",
    "        x2 = int((x_center + bbox_w / 2) * w)\n",
    "        y2 = int((y_center + bbox_h / 2) * h)\n",
    "        \n",
    "        # Ensure at least 1/4th of the bbox area remains visible\n",
    "        bbox_area = (x2 - x1) * (y2 - y1)\n",
    "        max_occlusion_area = bbox_area * 0.75\n",
    "        min_size = max((x2 - x1) // 4, (y2 - y1) // 4)\n",
    "        max_size = int(min(x2 - x1, y2 - y1, (max_occlusion_area) ** 0.5))\n",
    "        \n",
    "        if min_size > 0 and max_size >= min_size:\n",
    "            box_size = random.randint(min_size, max_size)\n",
    "            occl_x1 = random.randint(x1, max(x1, x2 - box_size))\n",
    "            occl_y1 = random.randint(y1, max(y1, y2 - box_size))\n",
    "            occl_x2 = occl_x1 + box_size\n",
    "            occl_y2 = occl_y1 + box_size\n",
    "            color = random.choice(colors)\n",
    "            cv2.rectangle(img, (occl_x1, occl_y1), (occl_x2, occl_y2), color, -1)\n",
    "    \n",
    "    # Save modified image\n",
    "    save_path = os.path.join(save_folder, image_file)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "print(\"Occlusion augmentation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handles even Thin BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5081/5081 [02:14<00:00, 37.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occlusion augmentation completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "\n",
    "# Paths\n",
    "image_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\images\"\n",
    "label_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\labels\"\n",
    "save_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\shahei_bigger_thin\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Occlusion Parameters\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]  # Red, Green, Blue, Yellow\n",
    "\n",
    "# Process Images\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith('.jpg')]\n",
    "for image_file in tqdm(image_files):\n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.replace('.jpg', '.txt'))\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # Read YOLO labels\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = f.readlines()\n",
    "    \n",
    "    updated_labels = []\n",
    "    for label in labels:\n",
    "        parts = label.strip().split()\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        class_id, x_center, y_center, bbox_w, bbox_h = map(float, parts)\n",
    "        x1 = int((x_center - bbox_w / 2) * w)\n",
    "        y1 = int((y_center - bbox_h / 2) * h)\n",
    "        x2 = int((x_center + bbox_w / 2) * w)\n",
    "        y2 = int((y_center + bbox_h / 2) * h)\n",
    "        \n",
    "        # Bounding Box Area\n",
    "        bbox_area = (x2 - x1) * (y2 - y1)\n",
    "        max_occlusion_area = bbox_area * 0.75  # Max occlusion is 75% of bbox\n",
    "        min_occlusion_area = bbox_area * 0.25  # Min occlusion is 25% of bbox\n",
    "\n",
    "        # Compute min/max occlusion sizes\n",
    "        min_size = max(ceil((x2 - x1) / 4), ceil((y2 - y1) / 4), 5)  # Ensure minimum size is at least 5 pixels\n",
    "        max_size = int(min(x2 - x1, y2 - y1, (max_occlusion_area) ** 0.5))  # Ensure occlusion fits inside bbox\n",
    "\n",
    "        # Ensure occlusion is applied only if it meets the criteria\n",
    "        if min_size <= max_size:\n",
    "            box_size = random.randint(min_size, max_size)\n",
    "            \n",
    "            # Randomly place occlusion inside the bbox\n",
    "            occl_x1 = random.randint(x1, max(x1, x2 - box_size))\n",
    "            occl_y1 = random.randint(y1, max(y1, y2 - box_size))\n",
    "            occl_x2 = occl_x1 + box_size\n",
    "            occl_y2 = occl_y1 + box_size\n",
    "\n",
    "            # Choose random occlusion color\n",
    "            color = random.choice(colors)\n",
    "            cv2.rectangle(img, (occl_x1, occl_y1), (occl_x2, occl_y2), color, -1)\n",
    "\n",
    "    # Save modified image\n",
    "    save_path = os.path.join(save_folder, image_file)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "print(\"Occlusion augmentation completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25-75% area occlusion + overlap protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the occlusion covers 25%-75% of each bounding box\n",
    "MIN_OCCLUSION = 0.25\n",
    "MAX_OCCLUSION = 0.75\n",
    "ASPECT_RATIO_RANGE = (0.5, 2.0)\n",
    "\n",
    "def apply_occlusion(image, labels):\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    total_occluded_area = {}  # Track occlusion per person\n",
    "    for label in labels:\n",
    "        values = label.split()\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = map(float, values)\n",
    "        \n",
    "        x1 = int((x_center - bbox_width / 2) * width)\n",
    "        y1 = int((y_center - bbox_height / 2) * height)\n",
    "        x2 = int((x_center + bbox_width / 2) * width)\n",
    "        y2 = int((y_center + bbox_height / 2) * height)\n",
    "        \n",
    "        bbox_area = (x2 - x1) * (y2 - y1)\n",
    "        max_occlusion_area = MAX_OCCLUSION * bbox_area\n",
    "        min_occlusion_area = MIN_OCCLUSION * bbox_area\n",
    "        \n",
    "        if class_id not in total_occluded_area:\n",
    "            total_occluded_area[class_id] = 0\n",
    "        \n",
    "        # Prevent full occlusion\n",
    "        remaining_area = max_occlusion_area - total_occluded_area[class_id]\n",
    "        if remaining_area <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Generate occlusion size within remaining limits\n",
    "        occ_area = random.uniform(min_occlusion_area, min(remaining_area, max_occlusion_area))\n",
    "        aspect_ratio = random.uniform(*ASPECT_RATIO_RANGE)\n",
    "        occ_w = int((occ_area * aspect_ratio) ** 0.5)\n",
    "        occ_h = int((occ_area / aspect_ratio) ** 0.5)\n",
    "        \n",
    "        occ_x1 = random.randint(x1, max(x1, x2 - occ_w))\n",
    "        occ_y1 = random.randint(y1, max(y1, y2 - occ_h))\n",
    "        occ_x2 = occ_x1 + occ_w\n",
    "        occ_y2 = occ_y1 + occ_h\n",
    "        \n",
    "        # Ensure occlusion stays within bounding box\n",
    "        occ_x2 = min(occ_x2, x2)\n",
    "        occ_y2 = min(occ_y2, y2)\n",
    "        \n",
    "        total_occluded_area[class_id] += (occ_x2 - occ_x1) * (occ_y2 - occ_y1)\n",
    "        \n",
    "        # Random occlusion color (green or blue)\n",
    "        color = (0, 255, 0) if random.random() < 0.5 else (255, 0, 0)\n",
    "        image[occ_y1:occ_y2, occ_x1:occ_x2] = color\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Paths\n",
    "image_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\images\"\n",
    "label_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\labels\"\n",
    "output_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\shahei_area\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for image_file in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.replace(\".jpg\", \".txt\"))\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    with open(label_path, \"r\") as f:\n",
    "        labels = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    occluded_image = apply_occlusion(image, labels)\n",
    "    output_path = os.path.join(output_folder, image_file)\n",
    "    cv2.imwrite(output_path, occluded_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same with max set to 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Ensure the occlusion covers 25%-50% of each bounding box\n",
    "MIN_OCCLUSION = 0.25\n",
    "MAX_OCCLUSION = 0.50\n",
    "ASPECT_RATIO_RANGE = (0.5, 2.0)\n",
    "\n",
    "def apply_occlusion(image, labels):\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    total_occluded_area = {}  # Track occlusion per person\n",
    "    for label in labels:\n",
    "        values = label.split()\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = map(float, values)\n",
    "        \n",
    "        x1 = int((x_center - bbox_width / 2) * width)\n",
    "        y1 = int((y_center - bbox_height / 2) * height)\n",
    "        x2 = int((x_center + bbox_width / 2) * width)\n",
    "        y2 = int((y_center + bbox_height / 2) * height)\n",
    "        \n",
    "        bbox_area = (x2 - x1) * (y2 - y1)\n",
    "        max_occlusion_area = MAX_OCCLUSION * bbox_area\n",
    "        min_occlusion_area = MIN_OCCLUSION * bbox_area\n",
    "        \n",
    "        if class_id not in total_occluded_area:\n",
    "            total_occluded_area[class_id] = 0\n",
    "        \n",
    "        # Prevent full occlusion\n",
    "        remaining_area = max_occlusion_area - total_occluded_area[class_id]\n",
    "        if remaining_area <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Generate occlusion size within remaining limits\n",
    "        occ_area = random.uniform(min_occlusion_area, min(remaining_area, max_occlusion_area))\n",
    "        aspect_ratio = random.uniform(*ASPECT_RATIO_RANGE)\n",
    "        occ_w = int((occ_area * aspect_ratio) ** 0.5)\n",
    "        occ_h = int((occ_area / aspect_ratio) ** 0.5)\n",
    "        \n",
    "        occ_x1 = random.randint(x1, max(x1, x2 - occ_w))\n",
    "        occ_y1 = random.randint(y1, max(y1, y2 - occ_h))\n",
    "        occ_x2 = occ_x1 + occ_w\n",
    "        occ_y2 = occ_y1 + occ_h\n",
    "        \n",
    "        # Ensure occlusion stays within bounding box\n",
    "        occ_x2 = min(occ_x2, x2)\n",
    "        occ_y2 = min(occ_y2, y2)\n",
    "        \n",
    "        total_occluded_area[class_id] += (occ_x2 - occ_x1) * (occ_y2 - occ_y1)\n",
    "        \n",
    "        # Random occlusion color (green or blue)\n",
    "        color = (0, 255, 0) if random.random() < 0.5 else (255, 0, 0)\n",
    "        image[occ_y1:occ_y2, occ_x1:occ_x2] = color\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Paths\n",
    "image_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\images\"\n",
    "label_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\labels\"\n",
    "output_folder = r\"D:\\Akash\\Work\\AI\\2025\\TC03\\OC\\shahei_50\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "for image_file in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.replace(\".jpg\", \".txt\"))\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    with open(label_path, \"r\") as f:\n",
    "        labels = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    occluded_image = apply_occlusion(image, labels)\n",
    "    output_path = os.path.join(output_folder, image_file)\n",
    "    cv2.imwrite(output_path, occluded_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to :\n",
    "1. Calculate IOU (track occlucded area)\n",
    "2. Apply Occlusion\n",
    "\n",
    "#### Note :\n",
    "1. The aspect ratio range for occlusion boxes is set to (0.5, 2.0), meaning:\n",
    "    1. The occlusion box width can be half to twice the height.\n",
    "    2. This allows for rectangular occlusions but avoids extreme shapes (e.g., very long or very thin occlusions).\n",
    "2. Min and max occlusion is set to 0.5 and 0.25, meaning:\n",
    "    1. Min Occlusion 25% area of the box\n",
    "    2. Max Occlusion 50% area of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "# Ensure the occlusion covers 25%-50% of each bounding box\n",
    "MIN_OCCLUSION = 0.25\n",
    "MAX_OCCLUSION = 0.50\n",
    "ASPECT_RATIO_RANGE = (0.5, 2.0)\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def apply_occlusion(image, labels):\n",
    "    height, width, _ = image.shape\n",
    "    bboxes = []\n",
    "    for label in labels:\n",
    "        values = label.split()\n",
    "        class_id, x_center, y_center, bbox_width, bbox_height = map(float, values)\n",
    "        \n",
    "        x1 = int((x_center - bbox_width / 2) * width)\n",
    "        y1 = int((y_center - bbox_height / 2) * height)\n",
    "        x2 = int((x_center + bbox_width / 2) * width)\n",
    "        y2 = int((y_center + bbox_height / 2) * height)\n",
    "        \n",
    "        bboxes.append((x1, y1, x2, y2, class_id))\n",
    "    \n",
    "    occluded_areas = []  # To track already occluded areas\n",
    "    for x1, y1, x2, y2, class_id in bboxes:\n",
    "        if any(iou((x1, y1, x2, y2), occ) > 0.5 for occ in occluded_areas):\n",
    "            continue  # Skip if significant overlap with existing occlusion\n",
    "        \n",
    "        bbox_area = (x2 - x1) * (y2 - y1)\n",
    "        min_occlusion_area = MIN_OCCLUSION * bbox_area\n",
    "        max_occlusion_area = MAX_OCCLUSION * bbox_area\n",
    "        \n",
    "        occ_area = random.uniform(min_occlusion_area, max_occlusion_area)\n",
    "        aspect_ratio = random.uniform(*ASPECT_RATIO_RANGE)\n",
    "        occ_w = int((occ_area * aspect_ratio) ** 0.5)\n",
    "        occ_h = int((occ_area / aspect_ratio) ** 0.5)\n",
    "        \n",
    "        occ_x1 = random.randint(x1, max(x1, x2 - occ_w))\n",
    "        occ_y1 = random.randint(y1, max(y1, y2 - occ_h))\n",
    "        occ_x2 = min(occ_x1 + occ_w, x2)\n",
    "        occ_y2 = min(occ_y1 + occ_h, y2)\n",
    "        \n",
    "        occluded_areas.append((occ_x1, occ_y1, occ_x2, occ_y2))\n",
    "        \n",
    "        # # occlusion color set to black\n",
    "        # color = (0,0,0)\n",
    "        # image[occ_y1:occ_y2, occ_x1:occ_x2] = color\n",
    "        \n",
    "        # # Random occlusion color (green or blue)\n",
    "        # color = (0, 255, 0) if random.random() < 0.5 else (255, 0, 0)\n",
    "        # image[occ_y1:occ_y2, occ_x1:occ_x2] = color\n",
    "        \n",
    "        # Random occlusion color\n",
    "        color = tuple(random.randint(0, 255) for _ in range(3))\n",
    "        image[occ_y1:occ_y2, occ_x1:occ_x2] = color\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "Root folder should have 2 folders \"images\" and \"labels\" in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Process all images and labels\n",
    "root_folder = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\test\")\n",
    "image_folder = Path(root_folder , \"images\")\n",
    "label_folder = Path(root_folder , \"labels\")\n",
    "output_folder = Path(root_folder , \"Output\") \n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input format 2 (for yolo datset format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Process all images and labels\n",
    "\n",
    "occlusion_percentage = 10\n",
    "root_folder = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\") / f\"occlusion_{occlusion_percentage}\"\n",
    "\n",
    "for datatype in [\"train\", \"val\"]:\n",
    "    image_folder = Path(root_folder, \"images\", datatype)\n",
    "    label_folder = Path(root_folder,  \"labels\", datatype)\n",
    "    output_folder = Path(root_folder,  \"Output\", datatype) \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for image_file in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        image_path = Path(image_path)\n",
    "        label_path = os.path.join(label_folder, image_file.replace(\".jpg\", \".txt\"))\n",
    "        \n",
    "        if not os.path.exists(label_path):\n",
    "            continue\n",
    "        \n",
    "        # image = cv2.imread(fr\"{image_path}\")\n",
    "        # if image is None:\n",
    "        #     print(f\"Error: Unable to read image {image_path}\")\n",
    "        #     continue # Skip processing this image\n",
    "        # with open(label_path, \"r\") as f:\n",
    "        #     labels = f.read().strip().split(\"\\n\")\n",
    "        \n",
    "        # occluded_image = apply_occlusion(image, labels)\n",
    "        # output_path = os.path.join(output_folder, image_file)\n",
    "        # cv2.imwrite(output_path, occluded_image)\n",
    "        \n",
    "        # Reading image through pil as cv2 doesn't read images with special charecters \n",
    "        try:\n",
    "            # Use PIL to open the image and convert it to OpenCV format\n",
    "            pil_image = Image.open(image_path).convert(\"RGB\")\n",
    "            image = np.array(pil_image)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV\n",
    "        except Exception as e:\n",
    "            print(f\"Error: Unable to read image {image_path} - {e}\")\n",
    "            continue  # Skip processing this image\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            labels = f.read().strip().split(\"\\n\")\n",
    "        \n",
    "        occluded_image = apply_occlusion(image, labels)\n",
    "        output_path = os.path.join(output_folder, image_file)\n",
    "        cv2.imwrite(output_path, occluded_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Occlusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_file in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "    label_path = os.path.join(label_folder, image_file.replace(\".jpg\", \".txt\"))\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    with open(label_path, \"r\") as f:\n",
    "        labels = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    occluded_image = apply_occlusion(image, labels)\n",
    "    output_path = os.path.join(output_folder, image_file)\n",
    "    cv2.imwrite(output_path, occluded_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply % occlusion to dataset \n",
    "1. make dataset without occlusion applied to it\n",
    "2. run occlusion on the new dataset\n",
    "3. add the remaining images to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5% dataset...\n",
      "Processing 10% dataset...\n",
      "Processing 15% dataset...\n",
      "Processing 20% dataset...\n",
      "Processing 25% dataset...\n",
      "Occlusion dataset creation complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "dataset_root = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\")  # Change this to your dataset root\n",
    "train_images = dataset_root / \"images\" / \"train\"\n",
    "val_images = dataset_root / \"images\" / \"val\"\n",
    "train_labels = dataset_root / \"labels\" / \"train\"\n",
    "val_labels = dataset_root / \"labels\" / \"val\"\n",
    "\n",
    "# Percentage values\n",
    "percentages = [5, 10, 15, 20, 25]\n",
    "\n",
    "# Function to get image paths\n",
    "def get_image_paths(folder):\n",
    "    return sorted([p for p in folder.glob(\"*.jpg\")])\n",
    "\n",
    "def get_label_paths(folder):\n",
    "    return sorted([p for p in folder.glob(\"*.txt\")])\n",
    "\n",
    "# Get image and label paths\n",
    "train_image_paths = get_image_paths(train_images)\n",
    "val_image_paths = get_image_paths(val_images)\n",
    "train_label_paths = get_label_paths(train_labels)\n",
    "val_label_paths = get_label_paths(val_labels)\n",
    "\n",
    "# Compute total number of images for 25% subset\n",
    "total_images = len(train_image_paths) + len(val_image_paths)\n",
    "num_total_25 = int(total_images * 0.25)\n",
    "num_train_25 = int(num_total_25 * 0.9)  # 90% of 25%\n",
    "num_val_25 = num_total_25 - num_train_25  # 10% of 25%\n",
    "\n",
    "# Randomly select 25% subset\n",
    "random.seed(42)  # For reproducibility\n",
    "train_subset_25 = random.sample(list(zip(train_image_paths, train_label_paths)), num_train_25)\n",
    "val_subset_25 = random.sample(list(zip(val_image_paths, val_label_paths)), num_val_25)\n",
    "\n",
    "# Function to get progressive subsets\n",
    "def get_progressive_subsets(full_set, percentages):\n",
    "    subset_dict = {}\n",
    "    for p in percentages:\n",
    "        num = int(len(full_set) * (p / 25))  # Ensure subset is from 25%\n",
    "        subset_dict[p] = full_set[:num]  # Take a portion from sorted list\n",
    "    return subset_dict\n",
    "\n",
    "# Create progressive subsets\n",
    "train_subsets = get_progressive_subsets(train_subset_25, percentages)\n",
    "val_subsets = get_progressive_subsets(val_subset_25, percentages)\n",
    "\n",
    "# Create occlusion datasets without applying occlusion\n",
    "for p in percentages:\n",
    "    print(f\"Processing {p}% dataset...\")\n",
    "    \n",
    "    # Define occlusion folder structure\n",
    "    occlusion_root = dataset_root / f\"occlusion_{p}\"\n",
    "    occlusion_train_images = occlusion_root / \"images\" / \"train\"\n",
    "    occlusion_val_images = occlusion_root / \"images\" / \"val\"\n",
    "    occlusion_train_labels = occlusion_root / \"labels\" / \"train\"\n",
    "    occlusion_val_labels = occlusion_root / \"labels\" / \"val\"\n",
    "    \n",
    "    # Create directories\n",
    "    occlusion_train_images.mkdir(parents=True, exist_ok=True)\n",
    "    occlusion_val_images.mkdir(parents=True, exist_ok=True)\n",
    "    occlusion_train_labels.mkdir(parents=True, exist_ok=True)\n",
    "    occlusion_val_labels.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Copy train images and labels\n",
    "    for img_path, lbl_path in train_subsets[p]:\n",
    "        shutil.copy(img_path, occlusion_train_images / img_path.name)\n",
    "        shutil.copy(lbl_path, occlusion_train_labels / lbl_path.name)\n",
    "    \n",
    "    # Copy val images and labels\n",
    "    for img_path, lbl_path in val_subsets[p]:\n",
    "        shutil.copy(img_path, occlusion_val_images / img_path.name)\n",
    "        shutil.copy(lbl_path, occlusion_val_labels / lbl_path.name)\n",
    "\n",
    "print(\"Occlusion dataset creation complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking subset integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 5% subset...\n",
      "5% subset is correctly contained within 25%.\n",
      "Checking 10% subset...\n",
      "10% subset is correctly contained within 25%.\n",
      "Checking 15% subset...\n",
      "15% subset is correctly contained within 25%.\n",
      "Checking 20% subset...\n",
      "20% subset is correctly contained within 25%.\n",
      "Check complete.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define dataset root\n",
    "root = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\")\n",
    "\n",
    "# Define percentage sets\n",
    "percentages = [5, 10, 15, 20, 25]\n",
    "\n",
    "# Function to get all image names in a folder\n",
    "def get_image_names(folder):\n",
    "    return {p.name for p in folder.glob(\"*.jpg\")}\n",
    "\n",
    "# Get 25% dataset images\n",
    "occlusion_25_train = get_image_names(root / \"occlusion_25\" / \"images\" / \"train\")\n",
    "occlusion_25_val = get_image_names(root / \"occlusion_25\" / \"images\" / \"val\")\n",
    "\n",
    "# Check subsets\n",
    "for p in [5, 10, 15, 20]:\n",
    "    print(f\"Checking {p}% subset...\")\n",
    "    \n",
    "    occlusion_train = get_image_names(root / f\"occlusion_{p}\" / \"images\" / \"train\")\n",
    "    occlusion_val = get_image_names(root / f\"occlusion_{p}\" / \"images\" / \"val\")\n",
    "    \n",
    "    missing_train = occlusion_train - occlusion_25_train\n",
    "    missing_val = occlusion_val - occlusion_25_val\n",
    "    \n",
    "    if missing_train:\n",
    "        print(f\"Missing in {p}% train: {sorted(missing_train)}\")\n",
    "    if missing_val:\n",
    "        print(f\"Missing in {p}% val: {sorted(missing_val)}\")\n",
    "    \n",
    "    if not missing_train and not missing_val:\n",
    "        print(f\"{p}% subset is correctly contained within 25%.\")\n",
    "\n",
    "print(\"Check complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename files \n",
    "- Some special charecters where replaced with some randon kanji when occluding images.\n",
    "- This would rename them back to their original file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for x in [5, 10, 15, 20, 25]:\n",
    "    # Set your root directory here\n",
    "    root_dir = fr\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_{x}\"\n",
    "\n",
    "    # Define what you want to replace\n",
    "    old_str = \"ﾐ岱嫺\"\n",
    "    new_str = \"БЛ\"\n",
    "\n",
    "    # Walk through all subdirectories and files\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if old_str in filename:\n",
    "                old_path = os.path.join(dirpath, filename)\n",
    "                new_filename = filename.replace(old_str, new_str)\n",
    "                new_path = os.path.join(dirpath, new_filename)\n",
    "                os.rename(old_path, new_path)\n",
    "                print(f\"Renamed:\\n{old_path}\\n→ {new_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paste Labels from 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected labels distributed successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define dataset root\n",
    "dataset_root = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\")\n",
    "\n",
    "# Define occlusion folders\n",
    "occlusion_25_labels_train = dataset_root / \"occlusion_25\" / \"labels\" / \"train\"\n",
    "occlusion_25_labels_val = dataset_root / \"occlusion_25\" / \"labels\" / \"val\"\n",
    "\n",
    "# Percentages to update\n",
    "percentages = [5, 10, 15, 20]\n",
    "\n",
    "# Function to update labels\n",
    "def update_labels(occlusion_x, occlusion_25_labels):\n",
    "    occlusion_x_labels = dataset_root / f\"occlusion_{occlusion_x}\" / \"labels\"\n",
    "\n",
    "    for subset in [\"train\", \"val\"]:\n",
    "        occlusion_x_labels_subset = occlusion_x_labels / subset\n",
    "        occlusion_25_labels_subset = occlusion_25_labels / subset\n",
    "\n",
    "        for label_file in occlusion_x_labels_subset.glob(\"*.txt\"):\n",
    "            src_label = occlusion_25_labels_subset / label_file.name\n",
    "            if src_label.exists():\n",
    "                shutil.copy(src_label, label_file)\n",
    "\n",
    "# Update labels for all subsets\n",
    "for p in percentages:\n",
    "    update_labels(p, dataset_root / \"occlusion_25\" / \"labels\")\n",
    "\n",
    "print(\"Corrected labels distributed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with remaining unoccluded images for the final datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining images and labels merged successfully!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Define dataset root\n",
    "dataset_root = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\")\n",
    "\n",
    "# Define the original train and val dataset folders\n",
    "original_images_train = dataset_root / \"images\" / \"train\"\n",
    "original_images_val = dataset_root / \"images\" / \"val\"\n",
    "original_labels_train = dataset_root / \"labels\" / \"train\" \n",
    "original_labels_val = dataset_root / \"labels\" / \"val\" \n",
    "\n",
    "# Percentages to update\n",
    "percentages = [5, 10, 15, 20, 25]\n",
    "\n",
    "# Function to merge missing images and labels\n",
    "def merge_remaining(occlusion_x):\n",
    "    occlusion_x_images = dataset_root / \"post_occlusion\"/ f\"occlusion_{occlusion_x}\" / \"images\"\n",
    "    occlusion_x_labels = dataset_root / \"post_occlusion\"/ f\"occlusion_{occlusion_x}\" / \"labels\"\n",
    "\n",
    "    for subset, original_images, original_labels in [\n",
    "        (\"train\", original_images_train, original_labels_train),\n",
    "        (\"val\", original_images_val, original_labels_val),\n",
    "    ]:\n",
    "        occlusion_x_images_subset = occlusion_x_images / subset\n",
    "        occlusion_x_labels_subset = occlusion_x_labels / subset\n",
    "\n",
    "        # Ensure destination folders exist\n",
    "        occlusion_x_images_subset.mkdir(parents=True, exist_ok=True)\n",
    "        occlusion_x_labels_subset.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Merge images\n",
    "        for img_file in original_images.glob(\"*.jpg\"):\n",
    "            dest_img = occlusion_x_images_subset / img_file.name\n",
    "            if not dest_img.exists():  # Only copy if it doesn't exist\n",
    "                shutil.copy(img_file, dest_img)\n",
    "\n",
    "        # Merge labels\n",
    "        for lbl_file in original_labels.glob(\"*.txt\"):\n",
    "            dest_lbl = occlusion_x_labels_subset / lbl_file.name\n",
    "            if not dest_lbl.exists():  # Only copy if it doesn't exist\n",
    "                shutil.copy(lbl_file, dest_lbl)\n",
    "\n",
    "# Merge the remaining images and labels for all subsets\n",
    "for p in percentages:\n",
    "    merge_remaining(p)\n",
    "\n",
    "print(\"Remaining images and labels merged successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Discards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing occlusion_25...\n",
      "Processing occlusion_20...\n",
      "Processing occlusion_15...\n",
      "Processing occlusion_10...\n",
      "Processing occlusion_5...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# List your occlusion folders\n",
    "occlusion_folders = [\"occlusion_25\", \"occlusion_20\", \"occlusion_15\", \"occlusion_10\", \"occlusion_5\"]\n",
    "\n",
    "# Base path where your occlusion folders are\n",
    "base_path = Path(r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\")  # <-- CHANGE this to your actual path\n",
    "\n",
    "for folder_name in occlusion_folders:\n",
    "    print(f\"Processing {folder_name}...\")\n",
    "    folder_path = base_path / folder_name\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        labels_path = folder_path / \"labels\" / split\n",
    "        images_path = folder_path / \"images\" / split\n",
    "\n",
    "        if not labels_path.exists():\n",
    "            print(f\"Labels path {labels_path} does not exist, skipping.\")\n",
    "            continue\n",
    "\n",
    "        for label_file in labels_path.glob(\"*.txt\"):\n",
    "            if label_file.stat().st_size == 0:\n",
    "                image_file = images_path / label_file.with_suffix(\".jpg\").name\n",
    "                if not image_file.exists():\n",
    "                    # Sometimes image extensions are .png or others\n",
    "                    image_file = next(images_path.glob(label_file.stem + \".*\"), None)\n",
    "\n",
    "                print(f\"Deleting: {label_file} and {image_file}\")\n",
    "                label_file.unlink()  # delete label\n",
    "                if image_file and image_file.exists():\n",
    "                    image_file.unlink()  # delete image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete extra labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\classes.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\STILL360БЛxperience_STILL_Fair_Booth_at_CeMAT_2016_1_001911_part_4_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\STILL360БЛxperience_STILL_Fair_Booth_at_CeMAT_2016_1_002005_part_3_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\STILL360БЛxperience_STILL_Fair_Booth_at_CeMAT_2016_1_002428_part_2_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\STILL360БЛxperience_STILL_Fair_Booth_at_CeMAT_2016_1_002428_part_3_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour1_000869_part_4_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour1_000905_part_3_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour1_001072_part_3_1.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour1_004511_part_2_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour1_004878_part_1_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour2_000906_part_3_1.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\train\\Toyota_VR_360ﾐ岱媽Factory_Tour4_002204_part_3_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\val\\classes.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\val\\STILL360БЛxperience_STILL_Fair_Booth_at_CeMAT_2016_1_001871_part_2_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\val\\Toyota_VR_360БЛFactory_Tour1_000874_part_3_2.txt\n",
      "Deleting extra label: D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\\labels\\val\\Toyota_VR_360БЛFactory_Tour2_002294_part_1_1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_dir = fr\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\post_occlusion\\occlusion_25\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    labels_dir = os.path.join(root_dir, \"labels\", split)\n",
    "    images_dir = os.path.join(root_dir, \"images\", split)\n",
    "\n",
    "    # Get all image names without extensions\n",
    "    image_basenames = set(os.path.splitext(f)[0] for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png')))\n",
    "    label_files = [f for f in os.listdir(labels_dir) if f.lower().endswith('.txt')]\n",
    "\n",
    "    for label_file in label_files:\n",
    "        label_basename = os.path.splitext(label_file)[0]\n",
    "        if label_basename not in image_basenames:\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            print(f\"Deleting extra label: {label_path}\")\n",
    "            os.remove(label_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final check of img and label integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking folder: 2025_04_tc04_dataset_10\n",
      "[train] All images and labels are correctly paired in 2025_04_tc04_dataset_10! 🎯\n",
      "[val] All images and labels are correctly paired in 2025_04_tc04_dataset_10! 🎯\n",
      "\n",
      "Checking folder: 2025_04_tc04_dataset_11\n",
      "[train] All images and labels are correctly paired in 2025_04_tc04_dataset_11! 🎯\n",
      "[val] All images and labels are correctly paired in 2025_04_tc04_dataset_11! 🎯\n",
      "\n",
      "Checking folder: 2025_04_tc04_dataset_12\n",
      "[train] All images and labels are correctly paired in 2025_04_tc04_dataset_12! 🎯\n",
      "[val] All images and labels are correctly paired in 2025_04_tc04_dataset_12! 🎯\n",
      "\n",
      "Checking folder: 2025_04_tc04_dataset_13\n",
      "[train] All images and labels are correctly paired in 2025_04_tc04_dataset_13! 🎯\n",
      "[val] All images and labels are correctly paired in 2025_04_tc04_dataset_13! 🎯\n",
      "\n",
      "Checking folder: 2025_04_tc04_dataset_14\n",
      "[train] All images and labels are correctly paired in 2025_04_tc04_dataset_14! 🎯\n",
      "[val] All images and labels are correctly paired in 2025_04_tc04_dataset_14! 🎯\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base root where all occlusion folders are\n",
    "base_root = r\"D:\\Akash\\Work\\AI\\2025\\TC04\\2025_01_tc1_dataset_01\\Final\"  # <- change this\n",
    "\n",
    "# List of occlusion folders\n",
    "occlusion_folders = [f\"{x}\" for x in [\"2025_04_tc04_dataset_10\", \"2025_04_tc04_dataset_11\", \"2025_04_tc04_dataset_12\", \"2025_04_tc04_dataset_13\", \"2025_04_tc04_dataset_14\"]]\n",
    "\n",
    "# Helper function to get file stems (without extension)\n",
    "def get_stems(folder, exts):\n",
    "    stems = set()\n",
    "    for filename in os.listdir(folder):\n",
    "        if any(filename.lower().endswith(ext) for ext in exts):\n",
    "            stems.add(os.path.splitext(filename)[0])\n",
    "    return stems\n",
    "\n",
    "# File extensions\n",
    "image_exts = {'.jpg', '.jpeg', '.png'}\n",
    "label_exts = {'.txt'}\n",
    "\n",
    "for folder in occlusion_folders:\n",
    "    root_dir = os.path.join(base_root, folder)\n",
    "    print(f\"\\nChecking folder: {folder}\")\n",
    "    \n",
    "    for split in [\"train\", \"val\"]:\n",
    "        images_folder = os.path.join(root_dir, \"images\", split)\n",
    "        labels_folder = os.path.join(root_dir, \"labels\", split)\n",
    "\n",
    "        # Get the stems\n",
    "        image_stems = get_stems(images_folder, image_exts)\n",
    "        label_stems = get_stems(labels_folder, label_exts)\n",
    "\n",
    "        images_missing_labels = image_stems - label_stems\n",
    "        labels_missing_images = label_stems - image_stems\n",
    "\n",
    "        if images_missing_labels:\n",
    "            print(f\"\\n[{split}] Images missing labels in {folder}:\")\n",
    "            for img_stem in images_missing_labels:\n",
    "                print(f\"{img_stem}\")\n",
    "\n",
    "        if labels_missing_images:\n",
    "            print(f\"\\n[{split}] Labels missing images in {folder}:\")\n",
    "            for lbl_stem in labels_missing_images:\n",
    "                print(f\"{lbl_stem}\")\n",
    "\n",
    "        if not images_missing_labels and not labels_missing_images:\n",
    "            print(f\"[{split}] All images and labels are correctly paired in {folder}! 🎯\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
