{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"D:\\Akash\\Work\\AI\\Dataset_research\\Occluded_REID\\whole_merge\\001.png\"\n",
    "save_path = r\"D:\\Akash\\Work\\AI\\GAN\\upscale\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Using OpenCV with Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the low-resolution image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Define new dimensions (e.g., 2x upscale)\n",
    "new_width = img.shape[1] * 6\n",
    "new_height = img.shape[0] * 6\n",
    "\n",
    "# Upscale the image using cubic interpolation\n",
    "upscaled_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Save or display the upscaled image\n",
    "cv2.imwrite(f\"{save_path}/upscaled_image_1.jpg\", upscaled_img)\n",
    "# cv2.imshow(\"Upscaled Image\", upscaled_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Using PIL with Antialiasing (for Smoothness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the low-resolution image\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Define the upscale factor (e.g., 2x)\n",
    "upscale_factor = 6\n",
    "new_size = (img.width * upscale_factor, img.height * upscale_factor)\n",
    "\n",
    "# Upscale with high-quality resampling\n",
    "upscaled_img = img.resize(new_size, Image.LANCZOS)\n",
    "upscaled_img.save(f\"{save_path}/upscaled_image_1(method2).jpg\")\n",
    "# upscaled_img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3: Using Real-ESRGAN for AI-based Upscaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.4.1+cu124\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: d:\\akash\\work\\ai\\model_evaluation_vscode\\evaluation\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: basicsr, facexlib, gfpgan, grad-cam, realesrgan, thop, torchaudio, torchcam, torchvision, ultralytics, ultralytics-thop\n",
      "---\n",
      "Name: torchvision\n",
      "Version: 0.19.1+cu124\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: d:\\akash\\work\\ai\\model_evaluation_vscode\\evaluation\\lib\\site-packages\n",
      "Requires: numpy, pillow, torch\n",
      "Required-by: basicsr, facexlib, gfpgan, grad-cam, realesrgan, ultralytics\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = r\"D:\\Akash\\Work\\AI\\GAN\\upscale\\best.pt\"\n",
    "img_path = r\"D:\\Akash\\Work\\AI\\GAN\\upscale\\001.png\"\n",
    "save_path = r\"D:\\Akash\\Work\\AI\\GAN\\upscale\\detect_001.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['best.pt'], source=img_path, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  2024-8-5 Python-3.8.10 torch-2.4.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 560, in <module>\n",
      "    main(opt)\n",
      "  File \"detect.py\", line 555, in main\n",
      "    run(**vars(opt))\n",
      "  File \"d:\\Akash\\Work\\AI\\model_evaluation_VSCODE\\evaluation\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"detect.py\", line 175, in run\n",
      "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
      "  File \"d:\\Akash\\Work\\AI\\model_evaluation_VSCODE\\yolov5\\models\\common.py\", line 467, in __init__\n",
      "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
      "  File \"d:\\Akash\\Work\\AI\\model_evaluation_VSCODE\\yolov5\\models\\experimental.py\", line 98, in attempt_load\n",
      "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
      "  File \"d:\\Akash\\Work\\AI\\model_evaluation_VSCODE\\evaluation\\lib\\site-packages\\ultralytics\\utils\\patches.py\", line 86, in torch_load\n",
      "    return _torch_load(*args, **kwargs)\n",
      "  File \"d:\\Akash\\Work\\AI\\model_evaluation_VSCODE\\evaluation\\lib\\site-packages\\torch\\serialization.py\", line 1097, in load\n",
      "    return _load(\n",
      "  File \"d:\\Akash\\Work\\AI\\model_evaluation_VSCODE\\evaluation\\lib\\site-packages\\torch\\serialization.py\", line 1525, in _load\n",
      "    result = unpickler.load()\n",
      "  File \"C:\\Users\\akash_wrozmxh\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\pathlib.py\", line 1044, in __new__\n",
      "    raise NotImplementedError(\"cannot instantiate %r on your system\"\n",
      "NotImplementedError: cannot instantiate 'PosixPath' on your system\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights best.pt --img 640 --conf 0.25 --source img_path  \n",
    "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
