{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name of datasets for which you want to create analysis videos\n",
    "test_datasets=[\n",
    "    \"raw_test_trimmed_concat\",\n",
    "    \"v360_test_trimmed_concat\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models for which you want to create analysis videos\n",
    "#copy the names as present in the NAS folder\n",
    "patterns=[\n",
    "    # #パターン0 2つのモデルを比較する\n",
    "    # [\n",
    "    #     \"240730181203_runs_train_2024_07_tc1_dataset_16\",\n",
    "    #     \"241019072903_runs_train_2024_10_tc5_dataset_11\"\n",
    "    # ],\n",
    "    # #パターン1 3つのモデルを比較する\n",
    "    # [\n",
    "    #     \"240714074724_runs_train_2024_07_dataset_13\",\n",
    "    #     \"240729114648_runs_train_2024_07_tc1_dataset_11\",\n",
    "    #     \"240614145641_runs_train_202403_7_BGs_2percent\"\n",
    "    # ],\n",
    "    #パターン2 4つのモデルを比較する\n",
    "    [\n",
    "        \"250412043905_runs_train_yolov8_2025_04_tc04_dataset_10\",\n",
    "        \"250412184923_runs_train_yolov8_2025_04_tc04_dataset_12\",\n",
    "        \"250412182550_runs_train_yolov8_2025_04_tc04_dataset_13\",\n",
    "        \"250413110224_runs_train_yolov8_2025_04_tc04_dataset_15\",\n",
    "    ],\n",
    "    # #パターン3 6つのモデルを比較する\n",
    "    # [\n",
    "    #     \"240714074724_runs_train_2024_07_dataset_13\",\n",
    "    #     \"240729114648_runs_train_2024_07_tc1_dataset_11\",\n",
    "    #     \"240730085130_runs_train_2024_07_tc1_dataset_14\",\n",
    "    #     \"240729110100_runs_train_2024_07_tc1_dataset_30\",\n",
    "    #     \"240715153347_runs_train_2024_07_dataset_22\",\n",
    "    #     \"240317121350_runs_train_HBI_mod_dataset_202403_7\"\n",
    "    # ],\n",
    "    # #パターン4 2つのモデルを比較する\n",
    "    # [\n",
    "    #     \"240614145641_runs_train_202403_7_BGs_2percent\",\n",
    "    #     \"240615143347_runs_train_202403_7_BGs_8percent\"\n",
    "    # ],\n",
    "    #パターン5 5つのモデルを比較する\n",
    "    # [\n",
    "    #     \"240730181203_runs_train_2024_07_tc1_dataset_16\",\n",
    "    #     \"240913174523_runs_train_2024_09_tc4_dataset_16\",\n",
    "    #     \"240914064403_runs_train_2024_09_tc4_dataset_17\",\n",
    "    #     \"240914063940_runs_train_2024_09_tc4_dataset_18\",\n",
    "    #     \"240914065043_runs_train_2024_09_tc4_dataset_19\"\n",
    "    # ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_01_tc1_dataset_11\n"
     ]
    }
   ],
   "source": [
    "\"_\".join(\"250127100726_runs_train_yolov8_2025_01_tc1_dataset_11_batch32\".split(\"_\")[4:9])  \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing 2 models\n",
    "def stack_videos1x2(input_videos, output_stacked_video_path, font_file_path, model_names):\n",
    "    ffmpeg_cmd = (\n",
    "        'ffmpeg -y ' +\n",
    "        '-i \"' + input_videos[0] + '\" ' +\n",
    "        '-i \"' + input_videos[1] + '\" ' +\n",
    "        '-filter_complex \"' +\n",
    "        '[0:v]drawtext=text=\\'' + model_names[0] + \"_Mix\" + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v0]; ' +\n",
    "        '[1:v]drawtext=text=\\'' + model_names[1] + \"_v360\" + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v1]; ' +\n",
    "        '[v0][v1]hstack=inputs=2[v]\" ' +\n",
    "        '-map \"[v]\" -preset ultrafast \"' + output_stacked_video_path + '\"'\n",
    "    )\n",
    "    subprocess.run(ffmpeg_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing 3 models\n",
    "def stack_videos1x3(input_videos, output_stacked_video_path, font_file_path, model_names):\n",
    "    ffmpeg_cmd = (\n",
    "        'ffmpeg -y ' +\n",
    "        '-i \"' + input_videos[0] + '\" ' +\n",
    "        '-i \"' + input_videos[1] + '\" ' +\n",
    "        '-i \"' + input_videos[2] + '\" ' +\n",
    "        '-filter_complex \"' +\n",
    "        '[0:v]drawtext=text=\\'' + model_names[0] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v0]; ' +\n",
    "        '[1:v]drawtext=text=\\'' + model_names[1] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v1]; ' +\n",
    "        '[2:v]drawtext=text=\\'' + model_names[2] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v2]; ' +\n",
    "        '[v0][v1][v2]hstack=inputs=3[v]\" ' +\n",
    "        '-map \"[v]\" -preset ultrafast \"' + output_stacked_video_path + '\"'\n",
    "    )\n",
    "    subprocess.run(ffmpeg_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing 4 models\n",
    "def stack_videos2x2(input_videos, output_stacked_video_path, font_file_path, model_names):\n",
    "    ffmpeg_cmd = (\n",
    "        'ffmpeg -y ' +\n",
    "        '-i \"' + input_videos[0] + '\" ' +\n",
    "        '-i \"' + input_videos[1] + '\" ' +\n",
    "        '-i \"' + input_videos[2] + '\" ' +\n",
    "        '-i \"' + input_videos[3] + '\" ' +\n",
    "        '-filter_complex \"' +\n",
    "        '[0:v]drawtext=text=\\'' + model_names[0] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v0]; ' +\n",
    "        '[1:v]drawtext=text=\\'' + model_names[1] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v1]; ' +\n",
    "        '[2:v]drawtext=text=\\'' + model_names[2] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v2]; ' +\n",
    "        '[3:v]drawtext=text=\\'' + model_names[3] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v3]; ' +\n",
    "        '[v0][v1]hstack=inputs=2[top]; ' +\n",
    "        '[v2][v3]hstack=inputs=2[bottom]; ' +\n",
    "        '[top][bottom]vstack=inputs=2[v]\" ' +\n",
    "        '-map \"[v]\" -preset ultrafast \"' + output_stacked_video_path + '\"'\n",
    "    )\n",
    "    subprocess.run(ffmpeg_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing 5 models\n",
    "def stack_videos2x3_blank(input_videos, output_stacked_video_path, font_file_path, model_names , vid_size):\n",
    "    ffmpeg_cmd = (\n",
    "        'ffmpeg -y ' +\n",
    "        '-i \"' + input_videos[0] + '\" ' +\n",
    "        '-i \"' + input_videos[1] + '\" ' +\n",
    "        '-i \"' + input_videos[2] + '\" ' +\n",
    "        '-i \"' + input_videos[3] + '\" ' +\n",
    "        '-i \"' + input_videos[4] + '\" ' +\n",
    "        '-f lavfi -i color=c=black:s=' + vid_size + ':d=5 ' +  # Add a blank black video as the 6th input\n",
    "        '-filter_complex \"' +\n",
    "        '[0:v]drawtext=text=\\'' + model_names[0] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v0]; ' +\n",
    "        '[1:v]drawtext=text=\\'' + model_names[1] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v1]; ' +\n",
    "        '[2:v]drawtext=text=\\'' + model_names[2] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v2]; ' +\n",
    "        '[3:v]drawtext=text=\\'' + model_names[3] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v3]; ' +\n",
    "        '[4:v]drawtext=text=\\'' + model_names[4] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v4]; ' +\n",
    "        '[5:v]drawtext=text=\\'\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v5]; ' +  # No text for the blank video\n",
    "        '[v0][v1][v2]hstack=inputs=3[top]; ' +\n",
    "        '[v3][v4][v5]hstack=inputs=3[bottom]; ' +\n",
    "        '[top][bottom]vstack=inputs=2[v]\" ' +\n",
    "        '-map \"[v]\" -preset ultrafast \"' + output_stacked_video_path + '\"'\n",
    "    )\n",
    "    subprocess.run(ffmpeg_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing 6 models\n",
    "def stack_videos2x3(input_videos, output_stacked_video_path, font_file_path,model_names):\n",
    "    ffmpeg_cmd = (\n",
    "        'ffmpeg -y ' +\n",
    "        '-i \"' + input_videos[0] + '\" ' +\n",
    "        '-i \"' + input_videos[1] + '\" ' +\n",
    "        '-i \"' + input_videos[2] + '\" ' +\n",
    "        '-i \"' + input_videos[3] + '\" ' +\n",
    "        '-i \"' + input_videos[4] + '\" ' +\n",
    "        '-i \"' + input_videos[5] + '\" ' +\n",
    "        '-filter_complex \"' +\n",
    "        '[0:v]drawtext=text=\\'' + model_names[0] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v0]; ' +\n",
    "        '[1:v]drawtext=text=\\'' + model_names[1] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v1]; ' +\n",
    "        '[2:v]drawtext=text=\\'' + model_names[2] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v2]; ' +\n",
    "        '[3:v]drawtext=text=\\'' + model_names[3] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v3]; ' +\n",
    "        '[4:v]drawtext=text=\\'' + model_names[4] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v4]; ' +\n",
    "        '[5:v]drawtext=text=\\'' + model_names[5] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v5]; ' +\n",
    "        '[v0][v1][v2]hstack=inputs=3[top]; ' +\n",
    "        '[v3][v4][v5]hstack=inputs=3[bottom]; ' +\n",
    "        '[top][bottom]vstack=inputs=2[v]\" ' +\n",
    "        '-map \"[v]\" -preset ultrafast \"' + output_stacked_video_path + '\"'\n",
    "    )\n",
    "    subprocess.run(ffmpeg_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing 9 models\n",
    "def stack_videos3x3(input_videos, output_stacked_video_path, font_file_path, model_names):\n",
    "    ffmpeg_cmd = (\n",
    "        'ffmpeg -y ' +\n",
    "        '-i \"' + input_videos[0] + '\" ' +\n",
    "        '-i \"' + input_videos[1] + '\" ' +\n",
    "        '-i \"' + input_videos[2] + '\" ' +\n",
    "        '-i \"' + input_videos[3] + '\" ' +\n",
    "        '-i \"' + input_videos[4] + '\" ' +\n",
    "        '-i \"' + input_videos[5] + '\" ' +\n",
    "        '-i \"' + input_videos[6] + '\" ' +\n",
    "        '-i \"' + input_videos[7] + '\" ' +\n",
    "        '-i \"' + input_videos[8] + '\" ' +\n",
    "        '-filter_complex \"' +\n",
    "        '[0:v]drawtext=text=\\'' + model_names[0] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v0]; ' +\n",
    "        '[1:v]drawtext=text=\\'' + model_names[1] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v1]; ' +\n",
    "        '[2:v]drawtext=text=\\'' + model_names[2] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v2]; ' +\n",
    "        '[3:v]drawtext=text=\\'' + model_names[3] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v3]; ' +\n",
    "        '[4:v]drawtext=text=\\'' + model_names[4] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v4]; ' +\n",
    "        '[5:v]drawtext=text=\\'' + model_names[5] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v5]; ' +\n",
    "        '[6:v]drawtext=text=\\'' + model_names[6] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v6]; ' +\n",
    "        '[7:v]drawtext=text=\\'' + model_names[7] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v7]; ' +\n",
    "        '[8:v]drawtext=text=\\'' + model_names[8] + '\\':fontfile=\\'' + font_file_path + '\\':fontsize=50:x=(w-text_w)/2:y=text_h:fontcolor=yellow[v8]; ' +\n",
    "        '[v0][v1][v2]hstack=inputs=3[row1]; ' +\n",
    "        '[v3][v4][v5]hstack=inputs=3[row2]; ' +\n",
    "        '[v6][v7][v8]hstack=inputs=3[row3]; ' +\n",
    "        '[row1][row2][row3]vstack=inputs=3[v]\" ' +\n",
    "        '-map \"[v]\" -preset ultrafast \"' + output_stacked_video_path + '\"'\n",
    "    )\n",
    "    subprocess.run(ffmpeg_cmd, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path where teisei videos are stored \n",
    "#the videos are retrieved from the basepath location for analysis\n",
    "basepath=r\"D:\\Akash\\Work\\AI\\2025\\TC04\\kaiseki\\teisei\"\n",
    "os.makedirs(basepath,exist_ok=True)\n",
    "models=os.listdir(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(pattern,dataset):\n",
    "    videos=[]\n",
    "    names=[]\n",
    "    for model in pattern:\n",
    "        if model in models:\n",
    "            dataset_path = os.path.join(basepath, model, dataset)\n",
    "            videos_list = [video for video in os.listdir(dataset_path) if video.endswith(\"_F1conf.mp4\")] \n",
    "            if len(videos_list) >0:   \n",
    "                for video in videos_list:\n",
    "                    model_name = model.split(\"runs_train_yolov8_\")[1]\n",
    "                    video_path = os.path.join(dataset_path, video)\n",
    "                    videos.append(video_path)\n",
    "                    names.append(model_name)\n",
    "            else: continue\n",
    "    return videos,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025_04_tc04_dataset_10', '2025_04_tc04_dataset_12', '2025_04_tc04_dataset_13', '2025_04_tc04_dataset_15']\n",
      "['2025_04_tc04_dataset_10', '2025_04_tc04_dataset_12', '2025_04_tc04_dataset_13', '2025_04_tc04_dataset_15']\n",
      "Stacking complete for pattern 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "save_path=r\"D:\\Akash\\Work\\AI\\2025\\TC04\\kaiseki\\teisei\\result\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "font_file_path=\"C\\\\:/Windows/fonts/consola.ttf\"\n",
    "counter=0\n",
    "for pattern in patterns:\n",
    "    save_dir=os.path.join(save_path,\"pattern\"+str(counter))\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    for dataset in test_datasets:\n",
    "        videos=[]\n",
    "        names=[]\n",
    "        videos,names=get_videos(pattern,dataset)\n",
    "        print(names)\n",
    "        if \"raw\" in dataset:\n",
    "            vid_size = \"800x800\"\n",
    "        else:\n",
    "            vid_size = \"1696x1696\"\n",
    "        out_videopath=os.path.join(save_dir,dataset+\".mp4\")\n",
    "        number_of_models=len(videos)\n",
    "        if number_of_models== 2: stack_videos1x2(videos, out_videopath, font_file_path, names)\n",
    "        elif number_of_models== 3: stack_videos1x3(videos, out_videopath, font_file_path, names)\n",
    "        elif number_of_models== 4: stack_videos2x2(videos, out_videopath, font_file_path, names)\n",
    "        elif number_of_models== 5: stack_videos2x3_blank(videos, out_videopath, font_file_path, names, vid_size)\n",
    "        elif number_of_models== 6: stack_videos2x3(videos, out_videopath, font_file_path, names)\n",
    "        elif number_of_models== 9: stack_videos3x3(videos, out_videopath, font_file_path, names)\n",
    "        else: print(\"Case did not match\")\n",
    "    print(\"Stacking complete for pattern \"+str(counter))\n",
    "    counter += 1       \n",
    "     \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
